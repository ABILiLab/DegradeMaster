{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8711034b-cbd4-4cdc-9493-70c77443602d",
   "metadata": {},
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "\n",
    "from io import StringIO\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def analyze_results(path):\n",
    "    with open('./eval/PROTAC_demo_saved.npy', 'rb') as f:\n",
    "        our_dic = np.load(f, allow_pickle=True).item()\n",
    "\n",
    "    with open('./eval/svm_saved.npy', 'rb') as f:\n",
    "        svm_dic = np.load(f, allow_pickle=True).item()\n",
    "\n",
    "    with open('./eval/rf_saved.npy', 'rb') as f:\n",
    "        rf_dic = np.load(f, allow_pickle=True).item()\n",
    "\n",
    "    with open('./latent/test_indices.pkl', 'rb') as f:\n",
    "        test_indices = pkl.load(f)\n",
    "\n",
    "    ids = test_indices['id']\n",
    "    test_indices = np.array(test_indices['indices'])\n",
    "\n",
    "    our_score, our_pred, our_label = our_dic['score'], our_dic['pred'], our_dic['label']\n",
    "    svm_score, svm_pred, svm_label = svm_dic['score'], svm_dic['pred'], svm_dic['label']\n",
    "    rf_score, rf_pred, rf_label = rf_dic['score'], rf_dic['pred'], rf_dic['label']\n",
    "\n",
    "    cor_l_ours, wro_l_svm, wro_l_rf = [], [], []\n",
    "    for i in range(len(our_label)):\n",
    "        if our_pred[i] == our_label[i]:\n",
    "            cor_l_ours.append(i)\n",
    "\n",
    "    for i in range(len(svm_label)):\n",
    "        if svm_pred[i] != svm_label[i]:\n",
    "            wro_l_svm.append(i)\n",
    "\n",
    "    for i in range(len(rf_label)):\n",
    "        if rf_pred[i] == rf_label[i]:\n",
    "            wro_l_rf.append(i)\n",
    "\n",
    "    # print(len(cor_l_ours), len(wro_l_svm), len(wro_l_rf))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(our_pred, our_label).ravel()\n",
    "    print('Ours: TN: {}, FP: {}, FN: {}, TP: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(svm_pred, svm_label).ravel()\n",
    "    print('SVM: TN: {}, FP: {}, FN: {}, TP: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(rf_pred, rf_label).ravel()\n",
    "    print('RF: TN: {}, FP: {}, FN: {}, TP: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "    svm_w_ours_c = []\n",
    "    for i in wro_l_svm:\n",
    "        if i in cor_l_ours:\n",
    "            svm_w_ours_c.append(i)\n",
    "\n",
    "    rf_w_ours_c = []\n",
    "    for i in wro_l_rf:\n",
    "        if i in cor_l_ours:\n",
    "            rf_w_ours_c.append(i)\n",
    "\n",
    "    print('svm_w_ours_c has number of {}: '.format(len(ids[svm_w_ours_c])), ids[svm_w_ours_c])\n",
    "    print('rf_w_ours_c has number of {}: '.format(len(ids[rf_w_ours_c])), ids[rf_w_ours_c])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77a9164-34d2-4bac-b100-21f4af7d3275",
   "metadata": {},
   "source": [
    "analyze_results('./eval/PROTAC_demo_saved.npy')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protac",
   "language": "python",
   "name": "protac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
